{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from io import StringIO\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE DATAFRAME OBJECT WITH USERDATA\n",
    "\n",
    "#Example link -- https://www.mountainproject.com/user/200169262/isaac-rubey\n",
    "rating_code_dict = { \n",
    "            1: [\"5.0\",\"5.0-\",\"5.0+\"], \n",
    "            2: [\"5.1\",\"5.1-\",\"5.1+\"], \n",
    "            3: [\"5.2\",\"5.2-\",\"5.2+\"], \n",
    "            4: [\"5.3\",\"5.3-\",\"5.3+\"], \n",
    "            5: [\"5.4\",\"5.4-\",\"5.4+\"], \n",
    "            6: [\"5.5\",\"5.5-\",\"5.5+\"], \n",
    "            7: [\"5.6\",\"5.6-\",\"5.6+\"], \n",
    "            8: [\"5.7\",\"5.7-\",\"5.7+\"], \n",
    "            9: [\"5.8\",\"5.8-\",\"5.8+\"], \n",
    "            10: [\"5.9\",\"5.9-\",\"5.9+\"],\n",
    "            12 : [\"5.10-\",\"5.10a/b\"],\n",
    "            16 : [\"5.10+\", \"5.10c/d\"], \n",
    "            11 : [\"5.10a\"],\n",
    "            13 : [\"5.10b\"],\n",
    "            15 : [\"5.10c\"],\n",
    "            17 : [\"5.10d\"],\n",
    "            14 : [\"5.10\",\"5.10b/c\"],\n",
    "            19 : [\"5.11-\",\"5.11a/b\"],\n",
    "            23 : [\"5.11+\",\"5.11c/d\"],\n",
    "            18 : [\"5.11a\"],\n",
    "            20 : [\"5.11b\"],\n",
    "            22 : [\"5.11c\"],\n",
    "            24 : [\"5.11d\"],\n",
    "            21 : [\"5.11\",\"5.11b/c\"],\n",
    "            26 : [\"5.12-\",\"5.12a/b\"],\n",
    "            30 : [\"5.12+\",\"5.12c/d\"],\n",
    "            25 : [\"5.12a\"],\n",
    "            27 : [\"5.12b\"],\n",
    "            29 : [\"5.12c\"],\n",
    "            31 : [\"5.12d\"],\n",
    "            28 : [\"5.12\",\"5.12b/c\"],\n",
    "            33 : [\"5.13-\",\"5.13a/b\"],\n",
    "            37 : [\"5.13+\",\"5.13c/d\"],\n",
    "            32 : [\"5.13a\"],\n",
    "            34 : [\"5.13b\"],\n",
    "            36 : [\"5.13c\"],\n",
    "            38 : [\"5.13d\"],\n",
    "            35 : [\"5.13\",\"5.13b/c\"],\n",
    "            40 : [\"5.14-\",\"5.14a/b\"],\n",
    "            44 : [\"5.14+\",\"5.14c/d\"],\n",
    "            39 : [\"5.14a\"],\n",
    "            41 : [\"5.14b\"],\n",
    "            43 : [\"5.14c\"],\n",
    "            45 : [\"5.14d\"],\n",
    "            42 : [\"5.14\",\"5.14b/c\"],\n",
    "            47 : [\"5.15-\", \"5.15a/b\"],\n",
    "            51 : [\"5.15+\",\"5.15c/d\"],\n",
    "            46 : [\"5.15a\"],\n",
    "            48 : [\"5.15b\"],\n",
    "            50 : [\"5.15c\"],\n",
    "            52 : [\"5.15d\"],\n",
    "            49 : [\"5.15\",\"5.15b/c\"],\n",
    "            101: [\"V-easy\"],\n",
    "            102: [\"V0\",\"V0-\",\"V0+\",\"V0-1\"],\n",
    "            103: [\"V1\",\"V1-\",\"V1+\",\"V1-2\"],\n",
    "            104: [\"V2\",\"V2-\",\"V2+\",\"V2-3\"],\n",
    "            105: [\"V3\",\"V3-\",\"V3+\",\"V3-4\"],\n",
    "            106: [\"V4\",\"V4-\",\"V4+\",\"V4-5\"],\n",
    "            107: [\"V5\",\"V5-\",\"V5+\",\"V5-6\"],\n",
    "            108: [\"V6\",\"V6-\",\"V6+\",\"V6-7\"],\n",
    "            109: [\"V7\",\"V7-\",\"V7+\",\"V7-8\"],\n",
    "            110: [\"V8\",\"V8-\",\"V8+\",\"V8-9\"],\n",
    "            111: [\"V9\",\"V9-\",\"V9+\",\"V9-10\"],\n",
    "            112: [\"V10\",\"V10-\",\"V10+\",\"V10-11\"],\n",
    "            113: [\"V11\",\"V11-\",\"V11+\",\"V11-12\"],\n",
    "            114: [\"V12\",\"V12-\",\"V12+\",\"V12-13\"],\n",
    "            115: [\"V13\",\"V13-\",\"V13+\",\"V13-14\"],\n",
    "            116: [\"V14\",\"V14-\",\"V14+\",\"V14-15\"],\n",
    "            117: [\"V15\",\"V15-\",\"V15+\",\"V15-16\"],\n",
    "            118: [\"V16\",\"V16-\",\"V16+\"],\n",
    "            119: [\"V17\",\"V17-\",\"V17+\"],\n",
    "            120: [\"V18\"],\n",
    "            201: [\"WI1\"],\n",
    "            202: [\"WI2\"],\n",
    "            203: [\"WI3\"],\n",
    "            204: [\"WI4\"],\n",
    "            205: [\"WI5\"],\n",
    "            206: [\"WI6\"],\n",
    "            207: [\"WI7\"],\n",
    "            208: [\"WI8\"],\n",
    "            301: [\"M1\"],\n",
    "            302: [\"M2\"],\n",
    "            303: [\"M3\"],\n",
    "            304: [\"M4\"],\n",
    "            305: [\"M5\"],\n",
    "            306: [\"M6\"],\n",
    "            307: [\"M7\"],\n",
    "            308: [\"M8\"],\n",
    "            309: [\"M9\"],\n",
    "            310: [\"M10\"],\n",
    "            311: [\"M11\"],\n",
    "            312: [\"M12\"],\n",
    "            313: [\"M13\"],\n",
    "            314: [\"M14\"],\n",
    "            315: [\"M15\"],\n",
    "            316: [\"M16\"],\n",
    "            317: [\"M17\"],\n",
    "            318: [\"M18\"],\n",
    "            319: [\"M19\"],\n",
    "            401: [\"A0\"],\n",
    "            402: [\"A1\"],\n",
    "            403: [\"A2\"],\n",
    "            404: [\"A3\"],\n",
    "            405: [\"A4\"],\n",
    "            501: [\"3rd\"],\n",
    "            502: [\"4th\"],\n",
    "            503: [\"5th\"],\n",
    "            601: [\"Snow\"],\n",
    "            701: [\"C0\"],\n",
    "            702: [\"C1\"],\n",
    "            703: [\"C2\"],\n",
    "            704: [\"C3\"],\n",
    "            705: [\"C4\"],\n",
    "            801: [\"AI0\"],\n",
    "            802: [\"AI1\"],\n",
    "            803: [\"AI2\"],\n",
    "            804: [\"AI3\"],\n",
    "            805: [\"AI4\"]\n",
    "            }\n",
    "\n",
    "usercsvlink = input(\"My MountainProject User Link: \")+\"/tick-export\"\n",
    "\n",
    "def create_df_ticklist(usercsvlink):\n",
    "    #Create master data frame with correct column names\n",
    "    user_df = pd.DataFrame(columns=('username', 'sex','age', 'date_accessed','tick_date','route_name', 'route_grade',\n",
    "    'user_grade', 'route_stars', 'user_stars','notes','route_url','number_of_pitches','location',\n",
    "    'style','lead_style','route_type', 'length','rating_code'))\n",
    "    \n",
    "    response = requests.get(usercsvlink, stream=False)\n",
    "    data = StringIO(str(response.content, 'utf-8'))\n",
    "    \n",
    "\n",
    "    #Create Dataframe object from user export csv\n",
    "    user_ticks = pd.read_csv(data)\n",
    "    user_ticks = user_ticks.rename(columns={'Date': 'tick_date', 'Route': 'route_name', 'Rating':'route_grade', 'Your Rating':'user_grade', \n",
    "                            'Notes':'notes','URL':'route_url', 'Pitches':'number_of_pitches','Location':'location',\n",
    "                            'Style':'style','Lead Style': 'lead_style','Route Type':'route_type',\n",
    "                            'Length':'length', 'Rating Code':'rating_code', 'Avg Stars':'route_stars', 'Your Stars':'user_stars'})\n",
    "\n",
    "    #get isolated username\n",
    "    url_parts = usercsvlink.split('/')\n",
    "    username = url_parts[-2].replace('-', ' ')\n",
    "\n",
    "    \n",
    "    #Getting demographics data by accessing userpage and scraping sex and age. \n",
    "    demo_url = usercsvlink[:-12]\n",
    "    \n",
    "    response = requests.get(demo_url, stream=False)\n",
    "    \n",
    "    html_content = response.text\n",
    "    \n",
    "    soup3 = BeautifulSoup(html_content, 'html.parser')\n",
    "    \n",
    "    demographics = soup3.find('div', {'class': 'col-xs-12 text-xs-center'})\n",
    "\n",
    "\n",
    "    if demographics is not None:\n",
    "        demographics_text = demographics.text.strip()\n",
    "    else:\n",
    "        demographics_text = None\n",
    "    \n",
    "    if not demographics_text or pd.isna(demographics_text):\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        if demographics_text is not None:\n",
    "            sex = re.findall('(Male|Female)', demographics_text)[0]\n",
    "        else:\n",
    "            sex = 'Unknown'\n",
    "    \n",
    "    except IndexError:\n",
    "        sex = 'Unknown'\n",
    "    \n",
    "    try:\n",
    "        age = re.findall('\\d+', demographics_text)[0]\n",
    "    except IndexError:\n",
    "        age = 0\n",
    "        \n",
    "    # add demographics data into dataframe\n",
    "    for index, row in user_ticks.iterrows():\n",
    "        user_ticks['username'] = username\n",
    "        user_ticks['date_accessed'] = datetime.now()\n",
    "        user_ticks['sex'] = sex\n",
    "        user_ticks['age'] = age\n",
    "    \n",
    "    #Replace rating_codes\n",
    "\n",
    "    rating_code = user_ticks['route_grade'].tolist()\n",
    "\n",
    "    rating_code = [string if string is not None else 'unknown' for string in rating_code]\n",
    "    rating_code = [str(string) for string in rating_code] \n",
    "\n",
    "    rating_code_lst = [] \n",
    "\n",
    "    for string in rating_code:\n",
    "        string_before_space = string.split(' ')[0]\n",
    "        for key, value in rating_code_dict.items():\n",
    "            if any(substring == string_before_space for substring in value):\n",
    "                rating_code_lst.append(key)\n",
    "                break\n",
    "        else:\n",
    "            rating_code_lst.append(0)\n",
    "\n",
    "\n",
    "    user_ticks['rating_code'] = rating_code_lst\n",
    "    \n",
    "    #Concat user_ticks with user_df to create final user_ticks object\n",
    "    user_ticks = pd.concat([user_df, user_ticks], axis = 0, ignore_index = True)\n",
    "\n",
    "\n",
    "    user_ticks['username'] = user_ticks['username'].astype(str)\n",
    "    user_ticks['sex'] = user_ticks['sex'].astype('category')\n",
    "    user_ticks['age'] = user_ticks['age'].astype(int)\n",
    "    user_ticks['date_accessed'] = user_ticks['date_accessed'].astype('datetime64')\n",
    "    user_ticks['tick_date'] = user_ticks['tick_date'].astype('datetime64')\n",
    "    user_ticks['route_name'] = user_ticks['route_name'].astype(str)\n",
    "    user_ticks['route_grade'] = user_ticks['route_grade'].astype(str)\n",
    "    user_ticks['user_grade'] = user_ticks['user_grade'].astype(str)\n",
    "    user_ticks['route_stars'] = user_ticks['route_stars'].astype('float32')\n",
    "    user_ticks['user_stars'] = user_ticks['user_stars'].astype(int)\n",
    "    user_ticks['notes'] = user_ticks['notes'].astype(str)\n",
    "    user_ticks['route_url'] = user_ticks['route_url'].astype(str)\n",
    "    user_ticks['number_of_pitches'] = user_ticks['number_of_pitches'].astype(int)\n",
    "    user_ticks['location'] = user_ticks['location'].astype(str)\n",
    "    user_ticks['style'] = user_ticks['style'].astype('category')\n",
    "    user_ticks['lead_style'] = user_ticks['lead_style'].astype('category')\n",
    "    user_ticks['route_type'] = user_ticks['route_type'].astype('category')\n",
    "    user_ticks['length'] = user_ticks['length'].fillna(0).astype(int)\n",
    "    user_ticks['rating_code'] = user_ticks['rating_code'].astype(int)\n",
    "\n",
    "    \n",
    "    return user_ticks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_user_ticks():\n",
    "    full_set = pd.read_csv(r'C:\\Users\\isaac\\OneDrive\\Documents\\Portfolio Project\\Mountain project data\\combined_users_full_data_set.csv')\n",
    "\n",
    "    full_set = full_set.rename(columns={'Date': 'tick_date', 'Route': 'route_name', 'Rating':'route_grade', 'Your Rating':'user_grade', \n",
    "                                'Notes':'notes','URL':'route_url', 'Pitches':'number_of_pitches','Location':'location',\n",
    "                                'Style':'style','Lead Style': 'lead_style','Route Type':'route_type',\n",
    "                                'Length':'length', 'Rating Code':'rating_code', 'Avg Stars':'route_stars', 'Your Stars':'user_stars'})\n",
    "\n",
    "\n",
    "\n",
    "    full_set['username'] = full_set['username'].astype(str)\n",
    "    full_set['sex'] = full_set['sex'].astype('category')\n",
    "    full_set['age'] = full_set['age'].astype(int)\n",
    "    full_set['date_accessed'] = full_set['date_accessed'].astype('datetime64[ns]')\n",
    "    full_set['tick_date'] = full_set['tick_date'].astype('datetime64[ns]')\n",
    "    full_set['route_name'] = full_set['route_name'].astype(str)\n",
    "    full_set['route_grade'] = full_set['route_grade'].astype(str)\n",
    "    full_set['user_grade'] = full_set['user_grade'].astype(str)\n",
    "    full_set['route_stars'] = full_set['route_stars'].astype('float32')\n",
    "    full_set['user_stars'] = full_set['user_stars'].astype(int)\n",
    "    full_set['notes'] = full_set['notes'].astype(str)\n",
    "    full_set['route_url'] = full_set['route_url'].astype(str)\n",
    "    full_set['number_of_pitches'] = full_set['number_of_pitches'].astype(int)\n",
    "    full_set['location'] = full_set['location'].astype(str)\n",
    "    full_set['style'] = full_set['style'].astype('category')\n",
    "    full_set['lead_style'] = full_set['lead_style'].astype('category')\n",
    "    full_set['route_type'] = full_set['route_type'].astype('category')\n",
    "    full_set['length'] = full_set['length'].fillna(0).astype(int)\n",
    "    full_set['rating_code'] = full_set['rating_code'].fillna(0).astype(int)\n",
    "    \n",
    "    \n",
    "    \n",
    "    rating_code_full_set = full_set['route_grade'].tolist()\n",
    "\n",
    "    rating_code_full_set = [string if string is not None else 'unknown' for string in rating_code_full_set]\n",
    "    rating_code_full_set = [str(string) for string in rating_code_full_set] \n",
    "\n",
    "    rating_code_list_full_set = [] \n",
    "\n",
    "    for string in rating_code_full_set:\n",
    "        string_before_space = string.split(' ')[0]\n",
    "        for key, value in rating_code_dict.items():\n",
    "            if any(substring == string_before_space for substring in value):\n",
    "                rating_code_list_full_set.append(key)\n",
    "                break\n",
    "        else:\n",
    "            rating_code_list_full_set.append(0)\n",
    "\n",
    "\n",
    "    full_set['rating_code'] = rating_code_list_full_set\n",
    "\n",
    "    \n",
    "\n",
    "    return full_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0    90\n",
      "9.0     74\n",
      "11.0    61\n",
      "12.0    60\n",
      "8.0     54\n",
      "15.0    43\n",
      "14.0    38\n",
      "13.0    23\n",
      "7.0     19\n",
      "17.0    19\n",
      "18.0    16\n",
      "16.0    15\n",
      "6.0      9\n",
      "5.0      8\n",
      "3.0      4\n",
      "1.0      4\n",
      "4.0      2\n",
      "21.0     1\n",
      "28.0     1\n",
      "Name: binned_code, dtype: int64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 626 entries, 0 to 625\n",
      "Data columns (total 20 columns):\n",
      " #   Column             Non-Null Count  Dtype         \n",
      "---  ------             --------------  -----         \n",
      " 0   username           626 non-null    object        \n",
      " 1   sex                626 non-null    category      \n",
      " 2   age                626 non-null    int32         \n",
      " 3   date_accessed      626 non-null    datetime64[ns]\n",
      " 4   tick_date          626 non-null    datetime64[ns]\n",
      " 5   route_name         626 non-null    object        \n",
      " 6   route_grade        626 non-null    object        \n",
      " 7   user_grade         626 non-null    object        \n",
      " 8   route_stars        626 non-null    float32       \n",
      " 9   user_stars         626 non-null    int32         \n",
      " 10  notes              626 non-null    object        \n",
      " 11  route_url          626 non-null    object        \n",
      " 12  number_of_pitches  626 non-null    int32         \n",
      " 13  location           626 non-null    object        \n",
      " 14  style              583 non-null    category      \n",
      " 15  lead_style         449 non-null    category      \n",
      " 16  route_type         626 non-null    category      \n",
      " 17  length             626 non-null    int32         \n",
      " 18  rating_code        626 non-null    int32         \n",
      " 19  binned_code        541 non-null    float64       \n",
      "dtypes: category(4), datetime64[ns](2), float32(1), float64(1), int32(5), object(7)\n",
      "memory usage: 67.2+ KB\n"
     ]
    }
   ],
   "source": [
    "lead_sends = ['Redpoint', 'Flash', 'Onsight', 'Pinkpoint']\n",
    "\n",
    "# bin sends to 3 per grade\n",
    "binned_code_dict = {\n",
    "    1: [\"5.0\",\"5.0-\",\"5.0+\"], \n",
    "    2: [\"5.1\",\"5.1-\",\"5.1+\"], \n",
    "    3: [\"5.2\",\"5.2-\",\"5.2+\"], \n",
    "    4: [\"5.3\",\"5.3-\",\"5.3+\"], \n",
    "    5: [\"5.4\",\"5.4-\",\"5.4+\"], \n",
    "    6: [\"5.5\",\"5.5-\",\"5.5+\"], \n",
    "    7: [\"5.6\",\"5.6-\",\"5.6+\"], \n",
    "    8: [\"5.7\",\"5.7-\",\"5.7+\"], \n",
    "    9: [\"5.8\",\"5.8-\",\"5.8+\"], \n",
    "    10: [\"5.9\",\"5.9-\",\"5.9+\"],\n",
    "    11: [\"5.10-\",\"5.10a\",\"5.10a/b\"],\n",
    "    12: [\"5.10\",\"5.10b\",\"5.10c\",\"5.10b/c\"],\n",
    "    13: [\"5.10+\",\"5.10c/d\", \"5.10d\"],\n",
    "    14: [\"5.11-\",\"5.11a\",\"5.11a/b\"],\n",
    "    15: [\"5.11\",\"5.11b\",\"5.11c\",\"5.11b/c\"],\n",
    "    16: [\"5.11+\",\"5.11c/d\", \"5.11d\"],\n",
    "    17: [\"5.12-\",\"5.12a\",\"5.12a/b\"],\n",
    "    18: [\"5.12\",\"5.12b\",\"5.12c\",\"5.12b/c\"],\n",
    "    19: [\"5.12+\",\"5.12c/d\",  \"5.12d\"],\n",
    "    20: [\"5.13-\",\"5.13a\",\"5.13a/b\"],\n",
    "    21: [\"5.13\",\"5.13b\",\"5.13c\",\"5.13b/c\"],\n",
    "    22: [\"5.13+\", \"5.13c/d\", \"5.13d\"],\n",
    "    23: [\"5.14-\",\"5.14a\",\"5.14a/b\"],\n",
    "    24: [\"5.14\",\"5.14b\",\"5.14c\",\"5.14b/c\"],\n",
    "    25: [ \"5.14+\",\"5.14c/d\", \"5.14d\"],\n",
    "    26: [\"5.15-\",\"5.15a\",\"5.15a/b\"],\n",
    "    27: [\"5.15\",\"5.15b\",\"5.15c\",\"5.15b/c\"],\n",
    "    28: [\"5.15+\",\"5.15c/d\",  \"5.15d\"]\n",
    "}\n",
    "\n",
    "\n",
    "# user_ticks_df\n",
    "user_ticks = create_df_ticklist(usercsvlink)\n",
    "\n",
    "\n",
    "# create column with binned ratings - 3 per number grade\n",
    "route_grades = user_ticks['route_grade'].fillna('unknown').astype(str).str.split(' ').str[0]\n",
    "user_ticks['binned_code'] = route_grades.apply(lambda rating: next((key for key, value in binned_code_dict.items() if rating in value), np.nan))\n",
    "\n",
    "#route filter var - sport sends\n",
    "route_sends = user_ticks[(user_ticks['lead_style'].isin(lead_sends)) & (user_ticks['rating_code'] < 100)]\n",
    "\n",
    "# Print value counts of the updated 'rating_code' column\n",
    "print(user_ticks['binned_code'].value_counts())\n",
    "\n",
    "# Print DataFrame information\n",
    "user_ticks.info()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quality of grade pyramid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grade Pyramid:\n",
      "5.12-: 3\n",
      "5.11+: 0\n",
      "5.11: 14\n",
      "5.11-: 20\n",
      "Chi-squared statistic (Steep): 0.27343559775992216\n",
      "p-value (Steep): 0.9649445669515759\n",
      "Chi-squared statistic (Shallow): 0.2052593133674215\n",
      "p-value (Shallow): 0.9767358322230109\n",
      "Your pyramid is shallow\n"
     ]
    }
   ],
   "source": [
    "pyramid_size = 50\n",
    "def grade_pyramid(pyramid_size):\n",
    "    # Filter down to user's top 50 lead sends\n",
    "    user_pyramid_df = route_sends.sort_values(by='binned_code', ascending=False).head(pyramid_size)\n",
    "\n",
    "    # Cuts off all ticks of the lowest grade in the pyramid, so no weird shapes\n",
    "    user_pyramid_df = user_pyramid_df[user_pyramid_df['binned_code'] != user_pyramid_df['binned_code'].min()]\n",
    "\n",
    "    # Calculating user pyramid distributions\n",
    "\n",
    "    # List of rating codes\n",
    "    rating_codes = list(binned_code_dict.keys())\n",
    "    counts = []\n",
    "\n",
    "    # Iterate through the rating codes occurrences in the dataframe\n",
    "    for value in rating_codes:\n",
    "        count = len(user_pyramid_df[user_pyramid_df['binned_code'] == value])\n",
    "        counts.append(count)\n",
    "\n",
    "    # Trim off zero values from counts\n",
    "    while len(counts) > 0 and counts[0] == 0:\n",
    "        counts = counts[1:]\n",
    "\n",
    "    while len(counts) > 0 and counts[-1] == 0:\n",
    "        counts = counts[:-1]\n",
    "\n",
    "    # Match the grades with the user distribution\n",
    "    grade_distribution = counts[::-1]\n",
    "\n",
    "    # Find max_rp_code\n",
    "    max_rp_code = user_pyramid_df['binned_code'].iloc[0]\n",
    "\n",
    "    # Create grades dictionary\n",
    "    grades_dict = {code: grades[0] for code, grades in binned_code_dict.items()}\n",
    "\n",
    "    # Create corresponding grades to pyramid\n",
    "    start_index = list(grades_dict.keys()).index(max_rp_code)\n",
    "    grades_list = [grades_dict[key] for key in list(grades_dict.keys())[start_index:start_index - len(grade_distribution):-1]]\n",
    "\n",
    "    # Print grade pyramid and corresponding frequencies\n",
    "    print(\"Grade Pyramid:\")\n",
    "    for grade, frequency in zip(grades_list, grade_distribution):\n",
    "        print(f\"{grade}: {frequency}\")\n",
    "\n",
    "    # Normalize the user distribution\n",
    "    sum_user = sum(grade_distribution)\n",
    "    user_distribution = [value / sum_user for value in grade_distribution]\n",
    "\n",
    "    # Define perfect distributions for steep and shallow\n",
    "    steep = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10,11,12,13,14,15,16,17,18,19,20]\n",
    "    shallow = [1, 3, 6, 12, 24, 48, 96,192,384,768,1534,3068]\n",
    "\n",
    "    # Normalize perfect distributions to have the same sum as user_distribution\n",
    "    sum_user_dist = sum(user_distribution)\n",
    "    perfect_distribution_steep = [value * sum_user_dist / sum(steep[:len(user_distribution)]) for value in steep[:len(user_distribution)]]\n",
    "    perfect_distribution_shallow = [value * sum_user_dist / sum(shallow[:len(user_distribution)]) for value in shallow[:len(user_distribution)]]\n",
    "\n",
    "    # Perform chi-squared test for steep distribution\n",
    "    chi2_stat_steep, p_value_steep = stats.chisquare(user_distribution, perfect_distribution_steep)\n",
    "    print(\"Chi-squared statistic (Steep):\", chi2_stat_steep)\n",
    "    print(\"p-value (Steep):\", p_value_steep)\n",
    "\n",
    "    # Perform chi-squared test for shallow distribution\n",
    "    chi2_stat_shallow, p_value_shallow = stats.chisquare(user_distribution, perfect_distribution_shallow)\n",
    "    print(\"Chi-squared statistic (Shallow):\", chi2_stat_shallow)\n",
    "    print(\"p-value (Shallow):\", p_value_shallow)\n",
    "\n",
    "    if p_value_shallow < p_value_steep:\n",
    "        print('Your pyramid is steep')\n",
    "    else:\n",
    "        print('Your pyramid is shallow')\n",
    "\n",
    "\n",
    "grade_pyramid(pyramid_size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variety of length - Count of types of climbs in past year bined by length, short, mid, long, multipitch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "short routes: 236\n",
      "medium routes: 198\n",
      "long routes: 133\n",
      "multipitch routes: 59\n",
      "626\n"
     ]
    }
   ],
   "source": [
    "length_df = user_ticks.copy()\n",
    "\n",
    "length_df.loc[(user_ticks['rating_code'] < 100) & (user_ticks['length'] != 0), 'route_length'] = user_ticks['length'] * user_ticks['number_of_pitches']\n",
    "\n",
    "\n",
    "# Define the bin ranges\n",
    "bins = [0, 50, 80, 130, 5000]\n",
    "labels = ['short', 'medium', 'long', 'multipitch']\n",
    "\n",
    "# Bin the 'length' values\n",
    "length_df['category'] = pd.cut(length_df['length'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "category_counts = length_df['category'].value_counts(sort=False, dropna=False)\n",
    "\n",
    "ordered_counts = category_counts.reindex(labels)\n",
    "\n",
    "for category, count in ordered_counts.items():\n",
    "    print(f'{category} routes: {count}')\n",
    "\n",
    "print(ordered_counts.sum())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variety of location - group climbes if they have simiar location names. have to decide on the right granularity..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(' Clear Creek Canyon ', 137), (' Shelf Road ', 74), (' North Table Mountain/Golden Cliffs ', 43), (' Castlewood Canyon SP ', 26), (' Red Rocks ', 25), (' Staunton State Park ', 25), (' Flatirons ', 23), (' Lookout Mountain Road ', 22), (' Boulder Canyon ', 18), (\" Devil's Head \", 16), (' Eldorado Canyon State Park ', 11), (' Redstone Area ', 11), (' Rifle Mountain Park ', 11), (' Main Elk Creek ', 10), (' Generic Area', 9), (' Piedra River ', 7), (' Saint George ', 7), (' Fume Wall ', 5), (' Mount Royal (near Frisco)', 5), (' Ridgway Dike Wall', 5), (' White Cliff', 5), (' Penitente Canyon ', 4), (' River Road ', 4), (' CO Hwy 7 & Tributaries ', 3), (' Diablo Canyon ', 3), (' Lime Park (a.k.a. Lime Creek) ', 3), (' Monitor Rock ', 3), (' The Urban Alpine Crag', 3), (' Wolcott Crags and Boulders ', 3), (' Deckers ', 2), (' Golden Gate Canyon SP ', 2), (' Goose Creek/Molly Gulch Campground ', 2), (' Hurd Creek Crag ', 2), (' The Narrows ', 2), (' The Promised Land ', 2), (' Transmitter Tower', 2), (' 191 South ', 1), (' Big Thompson Canyon ', 1), (' Castle Valley ', 1), (' Lumpy Ridge ', 1), (' Pipeline Wall', 1), (' Turkey Rocks ', 1), (' Waterfall Wall', 1)]\n",
      "Total unique locations: 43\n"
     ]
    }
   ],
   "source": [
    "\n",
    "truncated_locations = user_ticks[user_ticks['rating_code'] < 100]['location'].apply(lambda x: x.split('>')).apply(lambda x: x[:3])\n",
    "\n",
    "\n",
    "sorted_list = sorted(truncated_locations, key=lambda x: x[-1])\n",
    "\n",
    "# Count the occurrences of the same value\n",
    "counts = {}\n",
    "for sublist in sorted_list:\n",
    "    last_value = sublist[-1]\n",
    "    counts[last_value] = counts.get(last_value, 0) + 1\n",
    "\n",
    "user_location_counts = sorted(counts.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(user_location_counts)\n",
    "print('Total unique locations:', len(user_location_counts))\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Work Capasity - Pitches per Day - Vertical ft. per day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pitches per day: 3.1739130434782608\n",
      "vertical feet per day: length    226.980237\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "tot_vert = (length_df.loc[(length_df['rating_code'] < 100) & (length_df['category'] != 'multipitch'), ['length', 'number_of_pitches']]\n",
    "            .apply(lambda row: row['length'] * row['number_of_pitches'], axis=1)\n",
    "            .sum()) + length_df.loc[(length_df['rating_code'] < 100) & (length_df['category'] == 'multipitch'), ['length']].sum()\n",
    "\n",
    "tot_user_pitches = user_ticks[user_ticks['rating_code'] < 100]['number_of_pitches'].sum()\n",
    "\n",
    "tot_user_days = user_ticks[user_ticks['rating_code'] < 100]['tick_date'].nunique()\n",
    "\n",
    "pitches_per_day = tot_user_pitches / tot_user_days\n",
    "vert_per_day = tot_vert / tot_user_days\n",
    "\n",
    "print('pitches per day:', pitches_per_day)\n",
    "print('vertical feet per day:', vert_per_day)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How often a climber gets outside- Days per week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average days per week all time: 1.3798076923076923\n",
      "Average days per week in the past year: 1.2307692307692308\n",
      "Average days per week in the past 3 months: 1.3229571984435797\n"
     ]
    }
   ],
   "source": [
    "# BIN DATA BY WEEK\n",
    "weeks = user_ticks.copy()\n",
    "weeks['date'] = weeks['tick_date'].dt.floor('D')\n",
    "weekly_bins = weeks.groupby(pd.Grouper(key='date', freq='W')).date.nunique()\n",
    "days_per_week = weekly_bins.mean()\n",
    "print(\"Average days per week all time:\", days_per_week)\n",
    "\n",
    "# Calculate the current date\n",
    "current_date = datetime.now()\n",
    "\n",
    "# Define the start and end dates for the past year\n",
    "past_year_start = current_date - timedelta(days=365)\n",
    "past_year_end = current_date\n",
    "\n",
    "# Filter the DataFrame for the past year\n",
    "past_year_data = user_ticks[(user_ticks['tick_date'] >= past_year_start) & (user_ticks['tick_date'] <= past_year_end)]\n",
    "\n",
    "# Calculate the average number of unique days for the past year\n",
    "avg_days_per_week_past_year = past_year_data['tick_date'].dt.date.nunique() / 52\n",
    "print(\"Average days per week in the past year:\", avg_days_per_week_past_year)\n",
    "\n",
    "# Define the start and end dates for the past 3 months\n",
    "past_3_months_start = current_date - timedelta(days=90)\n",
    "past_3_months_end = current_date\n",
    "\n",
    "# Filter the DataFrame for the past 3 months\n",
    "past_3_months_data = user_ticks[(user_ticks['tick_date'] >= past_3_months_start) & (user_ticks['tick_date'] <= past_3_months_end)]\n",
    "\n",
    "# Calculate the average number of unique days for the past 3 months\n",
    "avg_days_per_week_past_3_months = past_3_months_data['tick_date'].dt.date.nunique() / 12.85\n",
    "print(\"Average days per week in the past 3 months:\", avg_days_per_week_past_3_months)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Types of climbing days by dificulty - Bin data by the volume of climbs on the same day, sum count of bins - Projecting, mid-grade, volume/mileage, mixed(?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid-grade         110\n",
      "project            75\n",
      "volume/mileage     68\n",
      "Name: day_category, dtype: int64\n",
      "253\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lead_sends = ['Redpoint', 'Flash', 'Onsight', 'Pinkpoint']\n",
    "\n",
    "#filter to route climbs\n",
    "daily_bins = user_ticks[(user_ticks['rating_code'] < 100)].copy()\n",
    "\n",
    "#apply the bined rating dictionary \n",
    "\n",
    "rating_code = daily_bins['route_grade'].fillna('unknown').astype(str).str.split(' ').str[0]\n",
    "bined_rating_code_lst = [next((key for key, value in bined_code_dict.items() if rating in value), 0) for rating in rating_code]\n",
    "\n",
    "daily_bins['rating_code'] = bined_rating_code_lst\n",
    "\n",
    "# split user_ticks by unique date, \n",
    "\n",
    "daily_bins.set_index('tick_date', inplace=True)\n",
    "\n",
    "daily_bins.sort_index(inplace=True) \n",
    "\n",
    "#add column with cumulative max rp\n",
    "\n",
    "filtered_bins = daily_bins[daily_bins['lead_style'].isin(lead_sends)].copy()\n",
    "\n",
    "\n",
    "daily_bins.loc[daily_bins['lead_style'].isin(lead_sends), 'highest_lead_to_date'] = filtered_bins['rating_code'].cummax()\n",
    "\n",
    "daily_bins['highest_lead_to_date'].fillna(method='ffill', inplace=True)\n",
    "\n",
    "#Calc medium rating code of ticks for the day\n",
    "\n",
    "daily_bins['rating_replicated'] = daily_bins.apply(lambda row: [row['rating_code']] * row['number_of_pitches'], axis=1)\n",
    "#calcing median using all rating code values\n",
    "#daily_median_rating_code = daily_bins.groupby('tick_date')['rating_replicated'].apply(lambda x: np.median(np.concatenate(x.values)) if len(x) > 1 else x.values[0])\n",
    "#removing lowest value before calculating median to account for warm up route \n",
    "daily_median_rating_code = daily_bins.groupby('tick_date')['rating_replicated'].apply(lambda x: np.median(np.concatenate(x.values)[1:]) if len(x) > 1 else x.values[0])\n",
    "\n",
    "\n",
    "daily_bins = daily_bins.join(daily_median_rating_code, on='tick_date', rsuffix='_median')\n",
    "\n",
    "#categorize day as 'project','mid-grade','volume/mileage' by how far they are from the 'highest_lead_to_date' value of the same day\n",
    "\n",
    "def categorize_day(row):\n",
    "    if np.median(row['rating_replicated_median']) >= row['highest_lead_to_date']-1:\n",
    "        return 'project'\n",
    "    elif np.median(row['rating_replicated_median']) >= row['highest_lead_to_date'] - 4:\n",
    "        return 'mid-grade'\n",
    "    else:\n",
    "        return 'volume/mileage'\n",
    "\n",
    "\n",
    "daily_bins['rating_replicated_median'] = daily_median_rating_code\n",
    "daily_bins['day_category'] = daily_bins.apply(categorize_day, axis=1)\n",
    "\n",
    "\n",
    "# Count category totals\n",
    "\n",
    "# Create a copy of daily_bins DataFrame\n",
    "unique_dates_df = daily_bins.copy()\n",
    "\n",
    "# Reset index to convert 'tick_date' from the index to a column\n",
    "unique_dates_df.reset_index(inplace=True)\n",
    "\n",
    "# Drop duplicates based on 'tick_date' and create a new DataFrame\n",
    "unique_dates_df = unique_dates_df.drop_duplicates(subset='tick_date').copy()\n",
    "\n",
    "# Set 'tick_date' as the index again\n",
    "unique_dates_df.set_index('tick_date', inplace=True)\n",
    "\n",
    "# Count category totals in the new DataFrame\n",
    "category_totals = unique_dates_df['day_category'].value_counts()\n",
    "\n",
    "print(category_totals)\n",
    "print(category_totals.sum())\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quality... user score or average pitch rating.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted Average Route Stars - All Time: 2.7391891\n",
      "Weighted Average Route Stars - Past Year: 3.0025973\n",
      "Weighted Average Route Stars - Past 3 Months: 3.083607\n",
      "Weighted Average User Stars - All Time: 2.6702127659574466\n",
      "Weighted Average User Stars - Past Year: 3.0779816513761467\n",
      "Weighted Average User Stars - Past 3 Months: 3.2181818181818183\n",
      "0      4.0\n",
      "1      4.0\n",
      "2      4.0\n",
      "3      4.0\n",
      "4      4.0\n",
      "      ... \n",
      "885    0.0\n",
      "886    3.0\n",
      "887    2.0\n",
      "888    2.0\n",
      "889    2.0\n",
      "Name: user_stars, Length: 890, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "avg_stars = user_ticks.copy()\n",
    "# Create a new DataFrame with duplicated rows based on 'number_of_pitches'\n",
    "avg_stars = avg_stars.reindex(avg_stars.index.repeat(avg_stars['number_of_pitches']))\n",
    "\n",
    "# Reset the index of the duplicated DataFrame\n",
    "avg_stars.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "# Replace -1 values in 'user_stars' column with NaN\n",
    "avg_stars['user_stars'] = avg_stars['user_stars'].replace(-1, np.nan)\n",
    "\n",
    "# Replace -1 values in 'route_stars' column with NaN\n",
    "avg_stars['route_stars'] = avg_stars['route_stars'].replace(-1, np.nan)\n",
    "\n",
    "\n",
    "\n",
    "# Calculate the weighted average route stars for all time, skipping NaN values\n",
    "weighted_avg_all_time = np.nanmean(avg_stars['route_stars'])\n",
    "\n",
    "# Filter the DataFrame for the past year\n",
    "past_year = avg_stars[avg_stars['tick_date'] >= pd.Timestamp.now() - pd.DateOffset(years=1)]\n",
    "\n",
    "# Calculate the weighted average route stars for the past year, skipping NaN values\n",
    "weighted_avg_past_year = np.nanmean(past_year['route_stars'])\n",
    "\n",
    "# Filter the DataFrame for the past 3 months\n",
    "past_3_months = avg_stars[avg_stars['tick_date'] >= pd.Timestamp.now() - pd.DateOffset(months=3)]\n",
    "\n",
    "# Calculate the weighted average route stars for the past 3 months, skipping NaN values\n",
    "weighted_avg_past_3_months = np.nanmean(past_3_months['route_stars'])\n",
    "\n",
    "# Print the weighted average route stars\n",
    "print(\"Weighted Average Route Stars - All Time:\", weighted_avg_all_time)\n",
    "print(\"Weighted Average Route Stars - Past Year:\", weighted_avg_past_year)\n",
    "print(\"Weighted Average Route Stars - Past 3 Months:\", weighted_avg_past_3_months)\n",
    "\n",
    "# Calculate the weighted average user stars for all time, skipping NaN values\n",
    "weighted_avg_all_time = np.nanmean(avg_stars['user_stars'])\n",
    "\n",
    "# Calculate the weighted average user stars for the past year, skipping NaN values\n",
    "weighted_avg_past_year = np.nanmean(past_year['user_stars'])\n",
    "\n",
    "# Calculate the weighted average user stars for the past 3 months, skipping NaN values\n",
    "weighted_avg_past_3_months = np.nanmean(past_3_months['user_stars'])\n",
    "\n",
    "# Print the weighted average user stars\n",
    "print(\"Weighted Average User Stars - All Time:\", weighted_avg_all_time)\n",
    "print(\"Weighted Average User Stars - Past Year:\", weighted_avg_past_year)\n",
    "print(\"Weighted Average User Stars - Past 3 Months:\", weighted_avg_past_3_months)\n",
    "\n",
    "\n",
    "print(avg_stars['user_stars'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
