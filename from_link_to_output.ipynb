{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from io import StringIO\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE DATAFRAME OBJECT WITH USERDATA\n",
    "\n",
    "#Example link -- https://www.mountainproject.com/user/200169262/isaac-rubey\n",
    "rating_code_dict = { \n",
    "            1: [\"5.0\",\"5.0-\",\"5.0+\"], \n",
    "            2: [\"5.1\",\"5.1-\",\"5.1+\"], \n",
    "            3: [\"5.2\",\"5.2-\",\"5.2+\"], \n",
    "            4: [\"5.3\",\"5.3-\",\"5.3+\"], \n",
    "            5: [\"5.4\",\"5.4-\",\"5.4+\"], \n",
    "            6: [\"5.5\",\"5.5-\",\"5.5+\"], \n",
    "            7: [\"5.6\",\"5.6-\",\"5.6+\"], \n",
    "            8: [\"5.7\",\"5.7-\",\"5.7+\"], \n",
    "            9: [\"5.8\",\"5.8-\",\"5.8+\"], \n",
    "            10: [\"5.9\",\"5.9-\",\"5.9+\"],\n",
    "            12 : [\"5.10-\",\"5.10a/b\"],\n",
    "            16 : [\"5.10+\", \"5.10c/d\"], \n",
    "            11 : [\"5.10a\"],\n",
    "            13 : [\"5.10b\"],\n",
    "            15 : [\"5.10c\"],\n",
    "            17 : [\"5.10d\"],\n",
    "            14 : [\"5.10\",\"5.10b/c\"],\n",
    "            19 : [\"5.11-\",\"5.11a/b\"],\n",
    "            23 : [\"5.11+\",\"5.11c/d\"],\n",
    "            18 : [\"5.11a\"],\n",
    "            20 : [\"5.11b\"],\n",
    "            22 : [\"5.11c\"],\n",
    "            24 : [\"5.11d\"],\n",
    "            21 : [\"5.11\",\"5.11b/c\"],\n",
    "            26 : [\"5.12-\",\"5.12a/b\"],\n",
    "            30 : [\"5.12+\",\"5.12c/d\"],\n",
    "            25 : [\"5.12a\"],\n",
    "            27 : [\"5.12b\"],\n",
    "            29 : [\"5.12c\"],\n",
    "            31 : [\"5.12d\"],\n",
    "            28 : [\"5.12\",\"5.12b/c\"],\n",
    "            33 : [\"5.13-\",\"5.13a/b\"],\n",
    "            37 : [\"5.13+\",\"5.13c/d\"],\n",
    "            32 : [\"5.13a\"],\n",
    "            34 : [\"5.13b\"],\n",
    "            36 : [\"5.13c\"],\n",
    "            38 : [\"5.13d\"],\n",
    "            35 : [\"5.13\",\"5.13b/c\"],\n",
    "            40 : [\"5.14-\",\"5.14a/b\"],\n",
    "            44 : [\"5.14+\",\"5.14c/d\"],\n",
    "            39 : [\"5.14a\"],\n",
    "            41 : [\"5.14b\"],\n",
    "            43 : [\"5.14c\"],\n",
    "            45 : [\"5.14d\"],\n",
    "            42 : [\"5.14\",\"5.14b/c\"],\n",
    "            47 : [\"5.15-\", \"5.15a/b\"],\n",
    "            51 : [\"5.15+\",\"5.15c/d\"],\n",
    "            46 : [\"5.15a\"],\n",
    "            48 : [\"5.15b\"],\n",
    "            50 : [\"5.15c\"],\n",
    "            52 : [\"5.15d\"],\n",
    "            49 : [\"5.15\",\"5.15b/c\"],\n",
    "            101: [\"V-easy\"],\n",
    "            102: [\"V0\",\"V0-\",\"V0+\",\"V0-1\"],\n",
    "            103: [\"V1\",\"V1-\",\"V1+\",\"V1-2\"],\n",
    "            104: [\"V2\",\"V2-\",\"V2+\",\"V2-3\"],\n",
    "            105: [\"V3\",\"V3-\",\"V3+\",\"V3-4\"],\n",
    "            106: [\"V4\",\"V4-\",\"V4+\",\"V4-5\"],\n",
    "            107: [\"V5\",\"V5-\",\"V5+\",\"V5-6\"],\n",
    "            108: [\"V6\",\"V6-\",\"V6+\",\"V6-7\"],\n",
    "            109: [\"V7\",\"V7-\",\"V7+\",\"V7-8\"],\n",
    "            110: [\"V8\",\"V8-\",\"V8+\",\"V8-9\"],\n",
    "            111: [\"V9\",\"V9-\",\"V9+\",\"V9-10\"],\n",
    "            112: [\"V10\",\"V10-\",\"V10+\",\"V10-11\"],\n",
    "            113: [\"V11\",\"V11-\",\"V11+\",\"V11-12\"],\n",
    "            114: [\"V12\",\"V12-\",\"V12+\",\"V12-13\"],\n",
    "            115: [\"V13\",\"V13-\",\"V13+\",\"V13-14\"],\n",
    "            116: [\"V14\",\"V14-\",\"V14+\",\"V14-15\"],\n",
    "            117: [\"V15\",\"V15-\",\"V15+\",\"V15-16\"],\n",
    "            118: [\"V16\",\"V16-\",\"V16+\"],\n",
    "            119: [\"V17\",\"V17-\",\"V17+\"],\n",
    "            120: [\"V18\"],\n",
    "            201: [\"WI1\"],\n",
    "            202: [\"WI2\"],\n",
    "            203: [\"WI3\"],\n",
    "            204: [\"WI4\"],\n",
    "            205: [\"WI5\"],\n",
    "            206: [\"WI6\"],\n",
    "            207: [\"WI7\"],\n",
    "            208: [\"WI8\"],\n",
    "            301: [\"M1\"],\n",
    "            302: [\"M2\"],\n",
    "            303: [\"M3\"],\n",
    "            304: [\"M4\"],\n",
    "            305: [\"M5\"],\n",
    "            306: [\"M6\"],\n",
    "            307: [\"M7\"],\n",
    "            308: [\"M8\"],\n",
    "            309: [\"M9\"],\n",
    "            310: [\"M10\"],\n",
    "            311: [\"M11\"],\n",
    "            312: [\"M12\"],\n",
    "            313: [\"M13\"],\n",
    "            314: [\"M14\"],\n",
    "            315: [\"M15\"],\n",
    "            316: [\"M16\"],\n",
    "            317: [\"M17\"],\n",
    "            318: [\"M18\"],\n",
    "            319: [\"M19\"],\n",
    "            401: [\"A0\"],\n",
    "            402: [\"A1\"],\n",
    "            403: [\"A2\"],\n",
    "            404: [\"A3\"],\n",
    "            405: [\"A4\"],\n",
    "            501: [\"3rd\"],\n",
    "            502: [\"4th\"],\n",
    "            503: [\"5th\"],\n",
    "            601: [\"Snow\"],\n",
    "            701: [\"C0\"],\n",
    "            702: [\"C1\"],\n",
    "            703: [\"C2\"],\n",
    "            704: [\"C3\"],\n",
    "            705: [\"C4\"],\n",
    "            801: [\"AI0\"],\n",
    "            802: [\"AI1\"],\n",
    "            803: [\"AI2\"],\n",
    "            804: [\"AI3\"],\n",
    "            805: [\"AI4\"]\n",
    "            }\n",
    "\n",
    "usercsvlink = input(\"My MountainProject User Link: \")+\"/tick-export\"\n",
    "\n",
    "def create_df_ticklist(usercsvlink):\n",
    "    #Create master data frame with correct column names\n",
    "    user_df = pd.DataFrame(columns=('username', 'sex','age', 'date_accessed','tick_date','route_name', 'route_grade',\n",
    "    'user_grade', 'route_stars', 'user_stars','notes','route_url','number_of_pitches','location',\n",
    "    'style','lead_style','route_type', 'length','rating_code'))\n",
    "    \n",
    "    response = requests.get(usercsvlink, stream=False)\n",
    "    data = StringIO(str(response.content, 'utf-8'))\n",
    "    \n",
    "\n",
    "    #Create Dataframe object from user export csv\n",
    "    user_ticks = pd.read_csv(data)\n",
    "    user_ticks = user_ticks.rename(columns={'Date': 'tick_date', 'Route': 'route_name', 'Rating':'route_grade', 'Your Rating':'user_grade', \n",
    "                            'Notes':'notes','URL':'route_url', 'Pitches':'number_of_pitches','Location':'location',\n",
    "                            'Style':'style','Lead Style': 'lead_style','Route Type':'route_type',\n",
    "                            'Length':'length', 'Rating Code':'rating_code', 'Avg Stars':'route_stars', 'Your Stars':'user_stars'})\n",
    "\n",
    "    #get isolated username\n",
    "    url_parts = usercsvlink.split('/')\n",
    "    username = url_parts[-2].replace('-', ' ')\n",
    "\n",
    "    \n",
    "    #Getting demographics data by accessing userpage and scraping sex and age. \n",
    "    demo_url = usercsvlink[:-12]\n",
    "    \n",
    "    response = requests.get(demo_url, stream=False)\n",
    "    \n",
    "    html_content = response.text\n",
    "    \n",
    "    soup3 = BeautifulSoup(html_content, 'html.parser')\n",
    "    \n",
    "    demographics = soup3.find('div', {'class': 'col-xs-12 text-xs-center'})\n",
    "\n",
    "\n",
    "    if demographics is not None:\n",
    "        demographics_text = demographics.text.strip()\n",
    "    else:\n",
    "        demographics_text = None\n",
    "    \n",
    "    if not demographics_text or pd.isna(demographics_text):\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        if demographics_text is not None:\n",
    "            sex = re.findall('(Male|Female)', demographics_text)[0]\n",
    "        else:\n",
    "            sex = 'Unknown'\n",
    "    \n",
    "    except IndexError:\n",
    "        sex = 'Unknown'\n",
    "    \n",
    "    try:\n",
    "        age = re.findall('\\d+', demographics_text)[0]\n",
    "    except IndexError:\n",
    "        age = 0\n",
    "        \n",
    "    # add demographics data into dataframe\n",
    "    for index, row in user_ticks.iterrows():\n",
    "        user_ticks['username'] = username\n",
    "        user_ticks['date_accessed'] = datetime.now()\n",
    "        user_ticks['sex'] = sex\n",
    "        user_ticks['age'] = age\n",
    "    \n",
    "    #Replace rating_codes\n",
    "\n",
    "    rating_code = user_ticks['route_grade'].tolist()\n",
    "\n",
    "    rating_code = [string if string is not None else 'unknown' for string in rating_code]\n",
    "    rating_code = [str(string) for string in rating_code] \n",
    "\n",
    "    rating_code_lst = [] \n",
    "\n",
    "    for string in rating_code:\n",
    "        string_before_space = string.split(' ')[0]\n",
    "        for key, value in rating_code_dict.items():\n",
    "            if any(substring == string_before_space for substring in value):\n",
    "                rating_code_lst.append(key)\n",
    "                break\n",
    "        else:\n",
    "            rating_code_lst.append(0)\n",
    "\n",
    "\n",
    "    user_ticks['rating_code'] = rating_code_lst\n",
    "    \n",
    "    #Concat user_ticks with user_df to create final user_ticks object\n",
    "    user_ticks = pd.concat([user_df, user_ticks], axis = 0, ignore_index = True)\n",
    "\n",
    "\n",
    "    user_ticks['username'] = user_ticks['username'].astype(str)\n",
    "    user_ticks['sex'] = user_ticks['sex'].astype('category')\n",
    "    user_ticks['age'] = user_ticks['age'].astype(int)\n",
    "    user_ticks['date_accessed'] = user_ticks['date_accessed'].astype('datetime64')\n",
    "    user_ticks['tick_date'] = user_ticks['tick_date'].astype('datetime64')\n",
    "    user_ticks['route_name'] = user_ticks['route_name'].astype(str)\n",
    "    user_ticks['route_grade'] = user_ticks['route_grade'].astype(str)\n",
    "    user_ticks['user_grade'] = user_ticks['user_grade'].astype(str)\n",
    "    user_ticks['route_stars'] = user_ticks['route_stars'].astype('float32')\n",
    "    user_ticks['user_stars'] = user_ticks['user_stars'].astype(int)\n",
    "    user_ticks['notes'] = user_ticks['notes'].astype(str)\n",
    "    user_ticks['route_url'] = user_ticks['route_url'].astype(str)\n",
    "    user_ticks['number_of_pitches'] = user_ticks['number_of_pitches'].astype(int)\n",
    "    user_ticks['location'] = user_ticks['location'].astype(str)\n",
    "    user_ticks['style'] = user_ticks['style'].astype('category')\n",
    "    user_ticks['lead_style'] = user_ticks['lead_style'].astype('category')\n",
    "    user_ticks['route_type'] = user_ticks['route_type'].astype('category')\n",
    "    user_ticks['length'] = user_ticks['length'].fillna(0).astype(int)\n",
    "    user_ticks['rating_code'] = user_ticks['rating_code'].astype(int)\n",
    "\n",
    "    \n",
    "    return user_ticks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_user_ticks():\n",
    "    full_set = pd.read_csv(r'C:\\Users\\isaac\\OneDrive\\Documents\\Portfolio Project\\Mountain project data\\combined_users_full_data_set.csv')\n",
    "\n",
    "    full_set = full_set.rename(columns={'Date': 'tick_date', 'Route': 'route_name', 'Rating':'route_grade', 'Your Rating':'user_grade', \n",
    "                                'Notes':'notes','URL':'route_url', 'Pitches':'number_of_pitches','Location':'location',\n",
    "                                'Style':'style','Lead Style': 'lead_style','Route Type':'route_type',\n",
    "                                'Length':'length', 'Rating Code':'rating_code', 'Avg Stars':'route_stars', 'Your Stars':'user_stars'})\n",
    "\n",
    "\n",
    "\n",
    "    full_set['username'] = full_set['username'].astype(str)\n",
    "    full_set['sex'] = full_set['sex'].astype('category')\n",
    "    full_set['age'] = full_set['age'].astype(int)\n",
    "    full_set['date_accessed'] = full_set['date_accessed'].astype('datetime64[ns]')\n",
    "    full_set['tick_date'] = full_set['tick_date'].astype('datetime64[ns]')\n",
    "    full_set['route_name'] = full_set['route_name'].astype(str)\n",
    "    full_set['route_grade'] = full_set['route_grade'].astype(str)\n",
    "    full_set['user_grade'] = full_set['user_grade'].astype(str)\n",
    "    full_set['route_stars'] = full_set['route_stars'].astype('float32')\n",
    "    full_set['user_stars'] = full_set['user_stars'].astype(int)\n",
    "    full_set['notes'] = full_set['notes'].astype(str)\n",
    "    full_set['route_url'] = full_set['route_url'].astype(str)\n",
    "    full_set['number_of_pitches'] = full_set['number_of_pitches'].astype(int)\n",
    "    full_set['location'] = full_set['location'].astype(str)\n",
    "    full_set['style'] = full_set['style'].astype('category')\n",
    "    full_set['lead_style'] = full_set['lead_style'].astype('category')\n",
    "    full_set['route_type'] = full_set['route_type'].astype('category')\n",
    "    full_set['length'] = full_set['length'].fillna(0).astype(int)\n",
    "    full_set['rating_code'] = full_set['rating_code'].fillna(0).astype(int)\n",
    "    \n",
    "    \n",
    "    \n",
    "    rating_code_full_set = full_set['route_grade'].tolist()\n",
    "\n",
    "    rating_code_full_set = [string if string is not None else 'unknown' for string in rating_code_full_set]\n",
    "    rating_code_full_set = [str(string) for string in rating_code_full_set] \n",
    "\n",
    "    rating_code_list_full_set = [] \n",
    "\n",
    "    for string in rating_code_full_set:\n",
    "        string_before_space = string.split(' ')[0]\n",
    "        for key, value in rating_code_dict.items():\n",
    "            if any(substring == string_before_space for substring in value):\n",
    "                rating_code_list_full_set.append(key)\n",
    "                break\n",
    "        else:\n",
    "            rating_code_list_full_set.append(0)\n",
    "\n",
    "\n",
    "    full_set['rating_code'] = rating_code_list_full_set\n",
    "\n",
    "    \n",
    "\n",
    "    return full_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\isaac\\AppData\\Local\\Temp\\ipykernel_23024\\2065251756.py:2: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  full_set = pd.read_csv(r'C:\\Users\\isaac\\OneDrive\\Documents\\Portfolio Project\\Mountain project data\\combined_users_full_data_set.csv')\n"
     ]
    }
   ],
   "source": [
    "user_ticks = create_df_ticklist(usercsvlink)\n",
    "full_set = process_full_set()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 14, 20]\n",
      "[['unknown'], ['unknown'], ['unknown'], ['unknown'], ['unknown'], ['unknown'], ['unknown'], ['unknown'], ['unknown'], ['unknown'], ['unknown'], ['unknown'], ['unknown'], ['unknown'], ['unknown'], ['unknown'], ['unknown'], ['unknown'], ['unknown'], ['unknown'], ['unknown'], ['unknown'], ['unknown'], ['unknown'], ['unknown'], ['unknown'], ['unknown'], ['unknown'], ['unknown'], ['unknown'], ['unknown'], ['unknown'], ['unknown'], ['unknown'], ['unknown'], ['unknown'], ['unknown']]\n"
     ]
    }
   ],
   "source": [
    "# Filter down to user's top 50 lead sends\n",
    "lead_sends = ['Redpoint', 'Flash', 'Onsight', 'Pinkpoint']\n",
    "user_sport_sends_by_grade = user_ticks[(user_ticks['lead_style'].isin(lead_sends)) & (user_ticks['rating_code'] < 100)].sort_values(by='rating_code', ascending=False)\n",
    "user_top_50_df = user_sport_sends_by_grade.head(50)\n",
    "user_pyramid_df = user_top_50_df.copy()\n",
    "\n",
    "# Alter rating code dictionary to bin sends to 3 per grade\n",
    "bined_code_dict = {\n",
    "    1: [\"5.0\",\"5.0-\",\"5.0+\"], \n",
    "    2: [\"5.1\",\"5.1-\",\"5.1+\"], \n",
    "    3: [\"5.2\",\"5.2-\",\"5.2+\"], \n",
    "    4: [\"5.3\",\"5.3-\",\"5.3+\"], \n",
    "    5: [\"5.4\",\"5.4-\",\"5.4+\"], \n",
    "    6: [\"5.5\",\"5.5-\",\"5.5+\"], \n",
    "    7: [\"5.6\",\"5.6-\",\"5.6+\"], \n",
    "    8: [\"5.7\",\"5.7-\",\"5.7+\"], \n",
    "    9: [\"5.8\",\"5.8-\",\"5.8+\"], \n",
    "    10: [\"5.9\",\"5.9-\",\"5.9+\"],\n",
    "    11: [\"5.10a\",\"5.10-\",\"5.10a/b\"],\n",
    "    12: [\"5.10b\",\"5.10c\",\"5.10\",\"5.10b/c\"],\n",
    "    13: [\"5.10c/d\", \"5.10+\", \"5.10d\"],\n",
    "    14: [\"5.11a\",\"5.11-\",\"5.11a/b\"],\n",
    "    15: [\"5.11b\",\"5.11c\",\"5.11\",\"5.11b/c\"],\n",
    "    16: [\"5.11c/d\", \"5.11+\", \"5.11d\"],\n",
    "    17: [\"5.12a\",\"5.12-\",\"5.12a/b\"],\n",
    "    18: [\"5.12b\",\"5.12c\",\"5.12\",\"5.12b/c\"],\n",
    "    19: [\"5.12c/d\", \"5.12+\", \"5.12d\"],\n",
    "    20: [\"5.13a\",\"5.13-\",\"5.13a/b\"],\n",
    "    21: [\"5.13b\",\"5.13c\",\"5.13\",\"5.13b/c\"],\n",
    "    22: [\"5.13c/d\", \"5.13+\", \"5.13d\"],\n",
    "    23: [\"5.14a\",\"5.14-\",\"5.14a/b\"],\n",
    "    24: [\"5.14b\",\"5.14c\",\"5.14\",\"5.14b/c\"],\n",
    "    25: [\"5.14c/d\", \"5.14+\", \"5.14d\"],\n",
    "    26: [\"5.15a\",\"5.15-\",\"5.15a/b\"],\n",
    "    27: [\"5.15b\",\"5.15c\",\"5.15\",\"5.15b/c\"],\n",
    "    28: [\"5.15c/d\", \"5.15+\", \"5.15d\"]\n",
    "}\n",
    "\n",
    "user_pyramid_df['bined_rating'] = user_pyramid_df['rating_code'].apply(lambda x: next((key for key, value in bined_code_dict.items() if x in value), 0))\n",
    "\n",
    "rating_code = user_pyramid_df['route_grade'].fillna('unknown').astype(str).str.split(' ').str[0]\n",
    "bined_rating_code_lst = [next((key for key, value in bined_code_dict.items() if rating in value), 0) for rating in rating_code]\n",
    "\n",
    "user_pyramid_df['rating_code'] = bined_rating_code_lst\n",
    "user_pyramid_df = user_pyramid_df[user_pyramid_df['rating_code'] != user_pyramid_df['rating_code'].min()]\n",
    "\n",
    "len_pyramid = len(user_pyramid_df)\n",
    "\n",
    "# Calculating user pyramid distributions\n",
    "user_distribution = user_pyramid_df['rating_code'].value_counts().sort_values(ascending=True).tolist()\n",
    "\n",
    "user_distribution_ratings = []\n",
    "for rating_code in user_pyramid_df['rating_code']:\n",
    "    rating = next((key for key, value in bined_code_dict.items() if rating_code in value), None)\n",
    "    if rating is not None:\n",
    "        user_distribution_ratings.append(bined_code_dict[rating])\n",
    "    else:\n",
    "        user_distribution_ratings.append(['unknown'])\n",
    "\n",
    "print(user_distribution)\n",
    "print(user_distribution_ratings)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quality of grade pyramid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter down to user's top 50 lead sends\n",
    "\n",
    "lead_sends = ['Redpoint', 'Flash', 'Onsight', 'Pinkpoint']\n",
    "\n",
    "user_sport_sends_by_grade = user_ticks[(user_ticks['lead_style'].isin(lead_sends)) & (user_ticks['rating_code'] < 100)].sort_values(by='rating_code', ascending=False)\n",
    "\n",
    "user_top_50_df = user_sport_sends_by_grade.head(50)\n",
    "\n",
    "user_pyramid_df = user_top_50_df.copy()\n",
    "\n",
    "#Alter rating code diction to bin sends to 3 per grade\n",
    "\n",
    "bined_code_dict = {\n",
    "    1: [\"5.0\",\"5.0-\",\"5.0+\",], \n",
    "    2: [\"5.1\",\"5.1-\",\"5.1+\"], \n",
    "    3: [\"5.2\",\"5.2-\",\"5.2+\"], \n",
    "    4: [\"5.3\",\"5.3-\",\"5.3+\"], \n",
    "    5: [\"5.4\",\"5.4-\",\"5.4+\"], \n",
    "    6: [\"5.5\",\"5.5-\",\"5.5+\"], \n",
    "    7: [\"5.6\",\"5.6-\",\"5.6+\"], \n",
    "    8: [\"5.7\",\"5.7-\",\"5.7+\"], \n",
    "    9: [\"5.8\",\"5.8-\",\"5.8+\"], \n",
    "    10: [\"5.9\",\"5.9-\",\"5.9+\"],\n",
    "    11 : [\"5.10-\",\"5.10a\",\"5.10a/b\"],\n",
    "    12 : [\"5.10\",\"5.10b\",\"5.10c\",\"5.10b/c\"],\n",
    "    13 : [\"5.10+\",\"5.10c/d\", \"5.10+\", \"5.10d\"],\n",
    "    14 : [\"5.11-\",\"5.11a\",\"5.11a/b\"],\n",
    "    15 : [\"5.11\",\"5.11b\",\"5.11c\",\"5.11b/c\"],\n",
    "    16 : [\"5.11+\",\"5.11c/d\",  \"5.11d\"],\n",
    "    17 : [\"5.12-\",\"5.12a\",\"5.12a/b\"],\n",
    "    18 : [\"5.12\",\"5.12b\",\"5.12c\",\"5.12b/c\"],\n",
    "    19 : [\"5.12+\",\"5.12c/d\",  \"5.12d\"],\n",
    "    20 : [\"5.13-\",\"5.13a\",\"5.13a/b\"],\n",
    "    21 : [\"5.13\",\"5.13b\",\"5.13c\",\"5.13b/c\"],\n",
    "    22 : [\"5.13+\", \"5.13c/d\", \"5.13d\"],\n",
    "    23 : [\"5.14-\",\"5.14a\",\"5.14a/b\"],\n",
    "    24 : [\"5.14\",\"5.14b\",\"5.14c\",\"5.14b/c\"],\n",
    "    25 : [\"5.14+\",\"5.14c/d\",  \"5.14d\"],\n",
    "    26 : [\"5.15-\",\"5.15a\",\"5.15a/b\"],\n",
    "    27 : [\"5.15\",\"5.15b\",\"5.15c\",\"5.15b/c\"],\n",
    "    28 : [\"5.15+\",\"5.15c/d\", \"5.15d\"]\n",
    "}\n",
    "\n",
    "\n",
    "rating_code = user_pyramid_df['route_grade'].fillna('unknown').astype(str).str.split(' ').str[0]\n",
    "bined_rating_code_lst = [next((key for key, value in bined_code_dict.items() if rating in value), 0) for rating in rating_code]\n",
    "\n",
    "\n",
    "user_pyramid_df['rating_code'] = bined_rating_code_lst\n",
    "\n",
    "user_pyramid_df = user_pyramid_df[user_pyramid_df['rating_code'] != user_pyramid_df['rating_code'].min()]\n",
    "\n",
    "len_pyramid = len(user_pyramid_df)\n",
    "\n",
    "#add bined rating column to give grades to associated bined values\n",
    "user_pyramid_df['bined_rating'] = user_pyramid_df['rating_code'].map(lambda x: bined_code_dict.get(x, [''])[0])\n",
    "\n",
    "\n",
    "# calculating user pyramid distributions\n",
    "\n",
    "# List of rating codes\n",
    "rating_codes = list(bined_code_dict.keys())  # Add your desired rating codes here\n",
    "\n",
    "counts = []\n",
    "\n",
    "# Iterate through the rating codes and count occurrences in the dataframe\n",
    "for value in rating_codes:\n",
    "    count = len(user_pyramid_df[user_pyramid_df['rating_code'] == value])\n",
    "    counts.append(count)\n",
    "\n",
    "# Trim off zero values \n",
    "while len(counts) > 0 and counts[0] == 0:\n",
    "    counts = counts[1:]\n",
    "\n",
    "while len(counts) > 0 and counts[-1] == 0:\n",
    "    counts = counts[:-1]\n",
    "\n",
    "# Calculate the user distribution including missing codes\n",
    "user_distribution = counts[::-1]\n",
    "\n",
    "\n",
    "\n",
    "# Normalize the user distribution\n",
    "sum_user = sum(user_distribution)\n",
    "user_distribution = [value / sum_user for value in user_distribution]\n",
    "\n",
    "\n",
    "steep = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "shallow = [1, 3, 6, 12, 24, 48]\n",
    "\n",
    "perfect_distribution_steep = []\n",
    "perfect_distribution_shallow = []\n",
    "\n",
    "for _ in range(len(user_distribution)):\n",
    "    value = steep.pop(0)\n",
    "    perfect_distribution_steep.append(value)\n",
    "\n",
    "for _ in range(len(user_distribution)):\n",
    "    value = shallow.pop(0)\n",
    "    perfect_distribution_shallow.append(value)\n",
    "\n",
    "sum_steep = sum(perfect_distribution_steep)\n",
    "sum_shallow = sum(perfect_distribution_shallow)\n",
    "\n",
    "\n",
    "perfect_distribution_steep = [value / sum_steep for value in perfect_distribution_steep]\n",
    "perfect_distribution_shallow = [value / sum_shallow for value in perfect_distribution_shallow]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi-squared statistic: 0.20843556654367468\n",
      "p-value: 0.9762161564867331\n"
     ]
    }
   ],
   "source": [
    "# Chi squared test\n",
    "expected = [(min_val + max_val) / 2 for min_val, max_val in zip(perfect_distribution_shallow, perfect_distribution_steep)]\n",
    "\n",
    "chi2_stat, p_value = stats.chisquare(user_distribution, expected)\n",
    "\n",
    "print(\"Chi-squared statistic:\", chi2_stat)\n",
    "print(\"p-value:\", p_value)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variety of length - Count of types of climbs in past year bined by length, short, mid, long, multipitch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "short routes: 236\n",
      "medium routes: 198\n",
      "long routes: 133\n",
      "multipitch routes: 59\n",
      "626\n"
     ]
    }
   ],
   "source": [
    "length_df = user_ticks.copy()\n",
    "\n",
    "length_df.loc[(user_ticks['rating_code'] < 100) & (user_ticks['length'] != 0), 'route_length'] = user_ticks['length'] * user_ticks['number_of_pitches']\n",
    "\n",
    "\n",
    "# Define the bin ranges\n",
    "bins = [0, 50, 80, 130, 5000]\n",
    "labels = ['short', 'medium', 'long', 'multipitch']\n",
    "\n",
    "# Bin the 'length' values\n",
    "length_df['category'] = pd.cut(length_df['length'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "category_counts = length_df['category'].value_counts(sort=False, dropna=False)\n",
    "\n",
    "ordered_counts = category_counts.reindex(labels)\n",
    "\n",
    "for category, count in ordered_counts.items():\n",
    "    print(f'{category} routes: {count}')\n",
    "\n",
    "print(ordered_counts.sum())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variety of location - group climbes if they have simiar location names. have to decide on the right granularity..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(' Clear Creek Canyon ', 137), (' Shelf Road ', 74), (' North Table Mountain/Golden Cliffs ', 43), (' Castlewood Canyon SP ', 26), (' Red Rocks ', 25), (' Staunton State Park ', 25), (' Flatirons ', 23), (' Lookout Mountain Road ', 22), (' Boulder Canyon ', 18), (\" Devil's Head \", 16), (' Eldorado Canyon State Park ', 11), (' Redstone Area ', 11), (' Rifle Mountain Park ', 11), (' Main Elk Creek ', 10), (' Generic Area', 9), (' Piedra River ', 7), (' Saint George ', 7), (' Fume Wall ', 5), (' Mount Royal (near Frisco)', 5), (' Ridgway Dike Wall', 5), (' White Cliff', 5), (' Penitente Canyon ', 4), (' River Road ', 4), (' CO Hwy 7 & Tributaries ', 3), (' Diablo Canyon ', 3), (' Lime Park (a.k.a. Lime Creek) ', 3), (' Monitor Rock ', 3), (' The Urban Alpine Crag', 3), (' Wolcott Crags and Boulders ', 3), (' Deckers ', 2), (' Golden Gate Canyon SP ', 2), (' Goose Creek/Molly Gulch Campground ', 2), (' Hurd Creek Crag ', 2), (' The Narrows ', 2), (' The Promised Land ', 2), (' Transmitter Tower', 2), (' 191 South ', 1), (' Big Thompson Canyon ', 1), (' Castle Valley ', 1), (' Lumpy Ridge ', 1), (' Pipeline Wall', 1), (' Turkey Rocks ', 1), (' Waterfall Wall', 1)]\n",
      "Total unique locations: 43\n"
     ]
    }
   ],
   "source": [
    "\n",
    "truncated_locations = user_ticks[user_ticks['rating_code'] < 100]['location'].apply(lambda x: x.split('>')).apply(lambda x: x[:3])\n",
    "\n",
    "\n",
    "sorted_list = sorted(truncated_locations, key=lambda x: x[-1])\n",
    "\n",
    "# Count the occurrences of the same value\n",
    "counts = {}\n",
    "for sublist in sorted_list:\n",
    "    last_value = sublist[-1]\n",
    "    counts[last_value] = counts.get(last_value, 0) + 1\n",
    "\n",
    "user_location_counts = sorted(counts.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(user_location_counts)\n",
    "print('Total unique locations:', len(user_location_counts))\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Work Capasity - Pitches per Day - Vertical ft. per day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pitches per day: 3.1739130434782608\n",
      "vertical feet per day: length    226.980237\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "tot_vert = (length_df.loc[(length_df['rating_code'] < 100) & (length_df['category'] != 'multipitch'), ['length', 'number_of_pitches']]\n",
    "            .apply(lambda row: row['length'] * row['number_of_pitches'], axis=1)\n",
    "            .sum()) + length_df.loc[(length_df['rating_code'] < 100) & (length_df['category'] == 'multipitch'), ['length']].sum()\n",
    "\n",
    "tot_user_pitches = user_ticks[user_ticks['rating_code'] < 100]['number_of_pitches'].sum()\n",
    "\n",
    "tot_user_days = user_ticks[user_ticks['rating_code'] < 100]['tick_date'].nunique()\n",
    "\n",
    "pitches_per_day = tot_user_pitches / tot_user_days\n",
    "vert_per_day = tot_vert / tot_user_days\n",
    "\n",
    "print('pitches per day:', pitches_per_day)\n",
    "print('vertical feet per day:', vert_per_day)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How often a climber gets outside- Days per week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average days per week all time: 1.3798076923076923\n",
      "Average days per week in the past year: 1.2307692307692308\n",
      "Average days per week in the past 3 months: 1.3229571984435797\n"
     ]
    }
   ],
   "source": [
    "# BIN DATA BY WEEK\n",
    "weeks = user_ticks.copy()\n",
    "weeks['date'] = weeks['tick_date'].dt.floor('D')\n",
    "weekly_bins = weeks.groupby(pd.Grouper(key='date', freq='W')).date.nunique()\n",
    "days_per_week = weekly_bins.mean()\n",
    "print(\"Average days per week all time:\", days_per_week)\n",
    "\n",
    "# Calculate the current date\n",
    "current_date = datetime.now()\n",
    "\n",
    "# Define the start and end dates for the past year\n",
    "past_year_start = current_date - timedelta(days=365)\n",
    "past_year_end = current_date\n",
    "\n",
    "# Filter the DataFrame for the past year\n",
    "past_year_data = user_ticks[(user_ticks['tick_date'] >= past_year_start) & (user_ticks['tick_date'] <= past_year_end)]\n",
    "\n",
    "# Calculate the average number of unique days for the past year\n",
    "avg_days_per_week_past_year = past_year_data['tick_date'].dt.date.nunique() / 52\n",
    "print(\"Average days per week in the past year:\", avg_days_per_week_past_year)\n",
    "\n",
    "# Define the start and end dates for the past 3 months\n",
    "past_3_months_start = current_date - timedelta(days=90)\n",
    "past_3_months_end = current_date\n",
    "\n",
    "# Filter the DataFrame for the past 3 months\n",
    "past_3_months_data = user_ticks[(user_ticks['tick_date'] >= past_3_months_start) & (user_ticks['tick_date'] <= past_3_months_end)]\n",
    "\n",
    "# Calculate the average number of unique days for the past 3 months\n",
    "avg_days_per_week_past_3_months = past_3_months_data['tick_date'].dt.date.nunique() / 12.85\n",
    "print(\"Average days per week in the past 3 months:\", avg_days_per_week_past_3_months)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Types of climbing days by dificulty - Bin data by the volume of climbs on the same day, sum count of bins - Projecting, mid-grade, volume/mileage, mixed(?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid-grade         110\n",
      "project            75\n",
      "volume/mileage     68\n",
      "Name: day_category, dtype: int64\n",
      "253\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lead_sends = ['Redpoint', 'Flash', 'Onsight', 'Pinkpoint']\n",
    "\n",
    "#filter to route climbs\n",
    "daily_bins = user_ticks[(user_ticks['rating_code'] < 100)].copy()\n",
    "\n",
    "\n",
    "#apply the bined rating dictionary \n",
    "\n",
    "rating_code = daily_bins['route_grade'].fillna('unknown').astype(str).str.split(' ').str[0]\n",
    "bined_rating_code_lst = [next((key for key, value in bined_code_dict.items() if rating in value), 0) for rating in rating_code]\n",
    "\n",
    "\n",
    "daily_bins['rating_code'] = bined_rating_code_lst\n",
    "\n",
    "\n",
    "# split user_ticks by unique date, \n",
    "\n",
    "daily_bins.set_index('tick_date', inplace=True)\n",
    "\n",
    "daily_bins.sort_index(inplace=True) \n",
    "\n",
    "#add column with cumulative max rp\n",
    "\n",
    "filtered_bins = daily_bins[daily_bins['lead_style'].isin(lead_sends)].copy()\n",
    "\n",
    "\n",
    "daily_bins.loc[daily_bins['lead_style'].isin(lead_sends), 'highest_lead_to_date'] = filtered_bins['rating_code'].cummax()\n",
    "\n",
    "daily_bins['highest_lead_to_date'].fillna(method='ffill', inplace=True)\n",
    "\n",
    "#Calc medium rating code of ticks for the day\n",
    "\n",
    "daily_bins['rating_replicated'] = daily_bins.apply(lambda row: [row['rating_code']] * row['number_of_pitches'], axis=1)\n",
    "#calcing median using all rating code values\n",
    "#daily_median_rating_code = daily_bins.groupby('tick_date')['rating_replicated'].apply(lambda x: np.median(np.concatenate(x.values)) if len(x) > 1 else x.values[0])\n",
    "#removing lowest value before calculating median to account for warm up route \n",
    "daily_median_rating_code = daily_bins.groupby('tick_date')['rating_replicated'].apply(lambda x: np.median(np.concatenate(x.values)[1:]) if len(x) > 1 else x.values[0])\n",
    "\n",
    "\n",
    "daily_bins = daily_bins.join(daily_median_rating_code, on='tick_date', rsuffix='_median')\n",
    "\n",
    "#categorize day as 'project','mid-grade','volume/mileage' by how far they are from the 'highest_lead_to_date' value of the same day\n",
    "\n",
    "def categorize_day(row):\n",
    "    if np.median(row['rating_replicated_median']) >= row['highest_lead_to_date']-1:\n",
    "        return 'project'\n",
    "    elif np.median(row['rating_replicated_median']) >= row['highest_lead_to_date'] - 4:\n",
    "        return 'mid-grade'\n",
    "    else:\n",
    "        return 'volume/mileage'\n",
    "\n",
    "\n",
    "daily_bins['rating_replicated_median'] = daily_median_rating_code\n",
    "daily_bins['day_category'] = daily_bins.apply(categorize_day, axis=1)\n",
    "\n",
    "\n",
    "# Count category totals\n",
    "\n",
    "# Create a copy of daily_bins DataFrame\n",
    "unique_dates_df = daily_bins.copy()\n",
    "\n",
    "# Reset index to convert 'tick_date' from the index to a column\n",
    "unique_dates_df.reset_index(inplace=True)\n",
    "\n",
    "# Drop duplicates based on 'tick_date' and create a new DataFrame\n",
    "unique_dates_df = unique_dates_df.drop_duplicates(subset='tick_date').copy()\n",
    "\n",
    "# Set 'tick_date' as the index again\n",
    "unique_dates_df.set_index('tick_date', inplace=True)\n",
    "\n",
    "# Count category totals in the new DataFrame\n",
    "category_totals = unique_dates_df['day_category'].value_counts()\n",
    "\n",
    "print(category_totals)\n",
    "print(category_totals.sum())\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quality... user score or average pitch rating.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Radar chart calcs\n",
    "1. pyramid quality\n",
    "2. Variety of lengths\n",
    "3. Variety of location\n",
    "4. pitches per day\n",
    "5. balance of types of climbing days\n",
    "6. Consistancy of getting out in past 3 mo"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
